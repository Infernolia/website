<!DOCTYPE HTML>
<html lang="en">
  <head>
    
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Aboli Marathe</title>

    <meta name="author" content="Aboli Marathe">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
  </head>
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-5L7DWSDLQ6"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-5L7DWSDLQ6');
</script>
  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                   Aboli Marathe
                </p>
                <p>I am a graduate student at <a href="https://www.cmu.edu">CMU</a> in <a href="https://www.ml.cmu.edu/">Machine Learning Department</a>, where I work on computer vision and learn about convex optimization. Pursuing my Masters in Machine Learning.
                </p>
                <p>
                  At NVIDIA I've worked on <a href="https://github.com/openhackathons-org/gpubootcamp">RAPIDS bootcamp material</a>.  I did my BE in Computer Engineering at <a href="https://pict.edu/">PICT</a>, where I performed research in perception for autonomous vehicles. I've received the <a href="https://www.computer.org/volunteering/awards/scholarships/merwin/merwin-winners/fall-2020-merwin-winners">IEEE Richard E. Merwin Scholarship</a> and am a Taekwondo Black Belt.
                </p>
                <p>
                  In recent years I've had the honor of working with (and learning from) some incredible people including Dr. Ketan Kotecha, Dr. Rahee Walambe and all my research collaborators.
                </p>
                <p>
                  I am actively looking for job opportunities in ML starting 2023, so if you have something interesting in mind, please reach out!
                </p>
                <p style="text-align:center">
                  <a href="mailto:aboli.rajan.marathe@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/abolimarathe/">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=VZTOHlQAAAAJ&hl=en">Google Scholar</a> &nbsp;/&nbsp;
                  <a href="https://twitter.com/Aboli_Marathe">Twitter</a> &nbsp;/&nbsp;
                  <a href="https://github.com/Infernolia/">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/aboli.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/aboli.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  I'm interested in computer vision, machine learning, generative artificial intelligence, and autonomous vehicles. Much of my research is about robust perception and extracting insights from aerial imagery. Representative papers are <span class="highlight">highlighted</span>.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          
    
      <tr onmouseout="zipnerf_stop()" onmouseover="zipnerf_start()"  bgcolor="#ffffd0">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <img src='images/wedge.png' width="160">
          </div>
         
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://infernolia.github.io/WEDGE/">
            <span class="papertitle">WEDGE: A multi-weather autonomous driving dataset built from generative vision-language models.</span>
          </a>
          <br>
          <strong>Aboli Marathe</strong>,
          <a href="https://www.cs.cmu.edu/~deva/">Deva Ramanan</a>,
          <a href="https://scholar.google.co.in/citations?user=Aa6m2TkAAAAJ&hl=en">Rahee Walambe</a>,
          <a href="https://scholar.google.co.in/citations?user=oNiE0gMAAAAJ&hl=en">Ketan Kotecha</a>
          <br>
          <em>CVPR</em>, 2023 &nbsp <font color="red"><strong>(Oral and Poster Presentation at Vision Datasets Understanding)</strong></font>
          <br>
          <a href="https://infernolia.github.io/WEDGE/">project page</a>
          /
          <a href="https://openaccess.thecvf.com/content/CVPR2023W/VDU/html/Marathe_WEDGE_A_Multi-Weather_Autonomous_Driving_Dataset_Built_From_Generative_Vision-Language_CVPRW_2023_paper.html">proceedings</a>
          /
          <a href="https://arxiv.org/abs/2305.07528">arXiv</a>
        
          <p></p>
          <p>
          Synthetic dataset of autonomous driving scenes by generative vision-language models. 
          </p>
        </td>
      </tr>
      
      
      <tr onmouseout="db3d_stop()" onmouseover="db3d_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <img src='images/proj0.png' width="160">
          </div>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://arxiv.org/abs/2204.01719">
            <span class="papertitle">RestoreX-AI: A Contrastive Approach Towards Guiding Image Restoration via Explainable AI Systems.</span>
          </a>
          <br>
          <strong>Aboli Marathe</strong>,
          <a href="https://www.linkedin.com/in/pushkar-jain-3280581b0">Pushkar Jain</a>,
          <a href="https://scholar.google.co.in/citations?user=Aa6m2TkAAAAJ&hl=en">Rahee Walambe</a>,
          <a href="https://scholar.google.co.in/citations?user=oNiE0gMAAAAJ&hl=en">Ketan Kotecha</a>
          <br>
          <em>CVPR</em>, 2022 &nbsp <font color="red"><strong>(Oral Presentation at Vision For All Seasons)</strong></font>
          <br>
          <a href="https://openaccess.thecvf.com/content/CVPR2022W/V4AS/papers/Marathe_RestoreX-AI_A_Contrastive_Approach_Towards_Guiding_Image_Restoration_via_Explainable_CVPRW_2022_paper.pdf">proceedings</a>
          /
          <a href="https://arxiv.org/abs/2204.01719">arXiv</a>
          <p></p>
          <p>
          Propose a contrastive approach towards mitigating generated object detection (OD) data corruptions, by evaluating images generated by restoration models during and post training. 
          </p>
        </td>
      </tr>


               <tr onmouseout="db3d_stop()" onmouseover="db3d_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <img src='images/projrl.png' width="160">
          </div>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://link.springer.com/chapter/10.1007/978-981-99-3250-4_22">
            <span class="papertitle">Segmented Œµ-Greedy for Solving a Redesigned Multi-arm Bandit Environment</span>
          </a>
          <br>
          A Shankar, M Diwan, <strong>Aboli Marathe</strong>, M Takalikar
          <br>
          <em>ADCIS</em>, 2022 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
          <br>
          <a href="https://link.springer.com/chapter/10.1007/978-981-99-3250-4_22">proceedings</a>
  
          <p></p>
          <p>
          Proposed a policy- ‚Äîsegmented Œµ -Greedy‚Äîthat allows the agent to pass through the environment while maximizing its returns along the way.
          </p>
        </td>
      </tr>

               <tr onmouseout="db3d_stop()" onmouseover="db3d_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <img src='images/projiccv.png' width="160">
          </div>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://openaccess.thecvf.com/content/ICCV2021W/ABAW/papers/Marathe_Evaluating_the_Performance_of_Ensemble_Methods_and_Voting_Strategies_for_ICCVW_2021_paper.pdf">
            <span class="papertitle">Evaluating the performance of ensemble methods and voting strategies for dense 2D pedestrian detection in the wild</span>
          </a>
          <br>
          <strong>Aboli Marathe</strong>,
          <a href="https://scholar.google.co.in/citations?user=Aa6m2TkAAAAJ&hl=en">Rahee Walambe</a>,
          <a href="https://scholar.google.co.in/citations?user=oNiE0gMAAAAJ&hl=en">Ketan Kotecha</a>
          <br>
          <em>ICCV</em>, 2021 &nbsp <font color="red"><strong>(Oral Presentation at Affective Behaviour Analysis in the Wild)</strong></font>
          <br>
          <a href="https://openaccess.thecvf.com/content/ICCV2021W/ABAW/papers/Marathe_Evaluating_the_Performance_of_Ensemble_Methods_and_Voting_Strategies_for_ICCVW_2021_paper.pdf">proceedings</a>
          <p></p>
          <p>
          In this work, we demonstrate the effectiveness of a lightweight ensemble architecture for pedestrian detection in the wild, which combines detectors and data augmentation techniques to improve the performance of well-established detectors 
          </p>
        </td>
      </tr>

               <tr onmouseout="db3d_stop()" onmouseover="db3d_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <img src='images/projcvpr.png' width="160">
          </div>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://arxiv.org/abs/2305.08302">
            <span class="papertitle">t-RAIN: Robust generalization under weather-aliasing label shift attacks</span>
          </a>
          <br>
          <strong>Aboli Marathe</strong>, S Prabhu
          <br>
          <em>CVPR</em>, 2023 &nbsp <font color="red"><strong>(Oral and Poster Presentation at Affective Behaviour Analysis in the Wild)</strong></font>
          <br>
          <a href="https://openaccess.thecvf.com/content/CVPR2023W/ABAW/html/Marathe_T-RAIN_Robust_Generalization_Under_Weather-Aliasing_Label_Shift_Attacks_CVPRW_2023_paper.html">proceedings</a>
          /
          <a href="https://arxiv.org/abs/2305.08302">arXiv</a>
                 
          <p></p>
          <p>
          We propose t-RAIN a similarity mapping technique for synthetic data augmentation using large scale generative models and evaluate the performance on DAWN dataset. This mapping boosts model test accuracy by 2.1, 4.4, 1.9, 2.7 % in no-shift, fog, snow, dust shifts respectively. 
          </p>
        </td>
      </tr>


               <tr onmouseout="db3d_stop()" onmouseover="db3d_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <img src='images/projdrones.png' width="160">
          </div>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://www.mdpi.com/2504-446X/5/3/66">
            <span class="papertitle">Multiscale object detection from drone imagery using ensemble transfer learning</span>
          </a>
          <br>
          
          <a href="https://scholar.google.co.in/citations?user=Aa6m2TkAAAAJ&hl=en">Rahee Walambe</a>,
          <strong>Aboli Marathe</strong>,
          <a href="https://scholar.google.co.in/citations?user=oNiE0gMAAAAJ&hl=en">Ketan Kotecha</a>
          <br>
          <em>Drones</em>, 2021 &nbsp <font color="red"><strong>(Editor's Choice Article)</strong></font>
          <br>
          <a href="https://www.mdpi.com/2504-446X/5/3/66">journal</a>
      
          <p></p>
          <p>
          Present an implementation of ensemble transfer learning to enhance the performance of the base models for multiscale object detection in drone imagery. 
          </p>
        </td>
      </tr>

               <tr onmouseout="db3d_stop()" onmouseover="db3d_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <img src='images/projhin.png' width="160">
          </div>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://www.hindawi.com/journals/cin/2021/5278820/">
            <span class="papertitle">Lightweight object detection ensemble framework for autonomous vehicles in challenging weather conditions</span>
          </a>
          <br>
          <a href="https://scholar.google.co.in/citations?user=Aa6m2TkAAAAJ&hl=en">Rahee Walambe</a>,
          <strong>Aboli Marathe</strong>,
          <a href="https://scholar.google.co.in/citations?user=oNiE0gMAAAAJ&hl=en">Ketan Kotecha</a>,
          George Ghinea
          <br>
          <em>Hindawi Computational Intelligence and Neuroscience  Special Issue Compression of Deep Learning Models for Resource-Constrained Devices</em>, 2021 &nbsp <font color="red"><strong></strong></font>
          <br>
          <a href="https://www.hindawi.com/journals/cin/2021/5278820/">journal</a>

          <p></p>
          <p>
         Ensembling multiple baseline deep learning models under different voting strategies for object detection and utilizing data augmentation to boost the models‚Äô performance is proposed to solve this problem. 
          </p>
        </td>
      </tr>


               <tr onmouseout="db3d_stop()" onmouseover="db3d_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <img src='images/projmars.png' width="160">
          </div>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://ieeexplore.ieee.org/abstract/document/9824518">
            <span class="papertitle">Mars Imagery Classification: A Galactic Battle between Knowledge Transfer Networks and their Dual-Attention Armed Adversaries</span>
          </a>
          <br>
          Geetanjali Kale, Anupam Patil, Pushkar Jain, Sameer Memon, Aniket Kulkarni, <strong>Aboli Marathe</strong>
          <br>
          <em> IEEE 7th International conference for Convergence in Technology (I2CT)</em>, 2022 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
          <br>
          <a href="https://ieeexplore.ieee.org/abstract/document/9824518">proceedings</a>

          <p></p>
          <p>
          In this work, we compare the performance of dual attention networks, interplanetary transfer learning methods and Vision transformers in classifying objects in images collected by the Mars Science Laboratory Curiosity rover from August 2012 to July 2015. 
          </p>
        </td>
      </tr>


            
     
          
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <h2>Miscellanea</h2>
              </td>
            </tr>
          </tbody></table>
          <table width="100%" align="center" border="0" cellpadding="20"><tbody>
            
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/tower.png"  width="160"></td>
              <td width="75%" valign="center">
                <a href="http://mlforsystems.org/">Reviewer for NIPS 2021: ML for Systems Workshop</a>
          <br>
                <a href="https://proceedings.mlr.press/v171/schrouff22a/schrouff22a.pdf">Reviewer for NIPS 2021: Algorithmic Fairness through the Lens of Causality and Robustness Workshop</a>
                <br>
                <a href="https://www.computer.org/volunteering/awards/scholarships/merwin/merwin-winners/fall-2020-merwin-winners">IEEE CS Richard E. Merwin Scholarship Winner 2020</a>
                <br>
                <a href="https://grandhack.mit.edu/boston-2020/">MIT Hacking Medicine Grand Hack 2020 Runner Up</a>
                <br>
                <a href="https://pict.edu/">1st Rank in All Departments F.E. (SGPA 10.0)</a>
              </td>
            </tr>
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/book.png" alt="pic"  width="160">
              </td>
              <td width="75%" valign="center">
                Course Work at CMU
                <br>
                <a href="https://www.stat.cmu.edu/~siva/teaching/700">36-700 (Probability and Mathematical Statistics), 10-701 (Introduction to Machine Learning (PhD)), 16-720 Computer Vision: CMU Fall 2022</a>
                <br>
                <a href="https://www.stat.cmu.edu/~siva/teaching/725/">10-725 (Convex Optimization), 10-708 (Probabilistic Graphical Models), 10-707 (Advanced Deep Learning): CMU Spring 2023</a>
                <br>

              </td>
            </tr>
            

           
            
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  The pictures (not photographs/paper icons) on this website are AI-generated images created using Midjourney. The source code for this website is based on the template provided by Jon Barron's <a href="https://github.com/jonbarron/jonbarron_website">source code</a>. 
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
